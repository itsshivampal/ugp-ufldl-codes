{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(fname):\n",
    "    image_data = loadmat(fname)['IMAGES']\n",
    "    image_rows = image_data.shape[0]\n",
    "    image_cols = image_data.shape[1]\n",
    "    n_images = image_data.shape[2]\n",
    "\n",
    "    n_patches = 10000\n",
    "    patch_rows = 8\n",
    "    patch_cols = 8\n",
    "    patches = np.zeros((patch_rows*patch_cols, n_patches), dtype=np.float64)\n",
    "\n",
    "    rows_diff = image_rows - patch_rows\n",
    "    cols_diff = image_cols - patch_cols\n",
    "    for i in range(n_patches):\n",
    "        image_id = np.random.randint(0, n_images)\n",
    "        x = np.random.randint(0, rows_diff)\n",
    "        y = np.random.randint(0, cols_diff)\n",
    "        patch = image_data[y:y+patch_rows, x:x+patch_cols, image_id].ravel()\n",
    "        patches[:, i] = patch\n",
    "\n",
    "    patches = normalize_data(patches)\n",
    "    return patches\n",
    "\n",
    "def normalize_data(patches):\n",
    "    patches -= patches.mean(axis=0)\n",
    "    pstd = 3.0 * np.std(patches)\n",
    "    patches = np.maximum(np.minimum(patches, pstd), -pstd) / pstd\n",
    "\n",
    "    patches = (patches + 1) * 0.4 + 0.1\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sample_images(\"IMAGES.mat\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z2):\n",
    "    return 1/(1 + np.exp(-1*z2))\n",
    "\n",
    "def sparse_autoencoder_cost(theta, visible_size, hidden_size, lambda_, sparsity_param, beta, data):\n",
    "    W1 = theta[:visible_size*hidden_size].reshape((hidden_size, visible_size))\n",
    "    W2 = theta[visible_size*hidden_size:2*hidden_size*visible_size].reshape((visible_size, hidden_size))\n",
    "    b1 = theta[2*hidden_size*visible_size:2*hidden_size*visible_size+hidden_size]\n",
    "    b2 = theta[2*hidden_size*visible_size+hidden_size:]\n",
    "    \n",
    "    m = data.shape[1]\n",
    "    \n",
    "    a1 = data\n",
    "    z2 = W1.dot(a1) + b1.reshape((-1, 1))\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = W2.dot(a2) + b2.reshape((-1, 1))\n",
    "    a3 = sigmoid(z3)\n",
    "    h = a3\n",
    "    y = a1\n",
    "    \n",
    "    rho = sparsity_param\n",
    "    rho_hat = np.mean(a2, axis = 1)\n",
    "    sparsity_delta = (-rho/rho_hat + (1.0 - rho)/(1.0 - rho_hat)).reshape((-1,1))\n",
    "    \n",
    "    delta3 = (h-y)*h*(1.0-h)\n",
    "    delta2 = (W2.T.dot(delta3) + beta*sparsity_delta)*a2*(1.0-a2)\n",
    "    \n",
    "    squared_error_term = np.sum((h-y)**2)/(2.0*m)\n",
    "    weight_decay = 0.5*lambda_*(np.sum(W1*W1) + np.sum(W2*W2))\n",
    "    sparsity_term = beta*np.sum(rho*np.log(rho/rho_hat) + (1.0-rho)*np.log((1.0-rho)/(1.0-rho_hat)))\n",
    "    cost = squared_error_term + weight_decay + sparsity_term\n",
    "    \n",
    "    W2_grad = delta3.dot(a2.T)/m + lambda_*W2\n",
    "    W1_grad = delta2.dot(a1.T)/m + lambda_*W1\n",
    "    b1_grad = np.mean(delta2, axis = 1)\n",
    "    b2_grad = np.mean(delta3, axis = 1)\n",
    "    grad = np.hstack((W1_grad.ravel(), W2_grad.ravel(), b1_grad, b2_grad))\n",
    "    \n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_quadratic_function(x):\n",
    "    value = x[0]*x[0] + 3*x[0]*x[1]\n",
    "    grad = np.zeros(2)\n",
    "    grad[0] = 2*x[0] + 3*x[1]\n",
    "    grad[1] = 3*x[0]\n",
    "    return value, grad\n",
    "\n",
    "def compute_numerical_gradient(J, theta):\n",
    "    n = theta.size\n",
    "    grad = np.zeros(n)\n",
    "    eps = 1.0e-4\n",
    "    eps2 = 2*eps\n",
    "    \n",
    "    for i in range(n):\n",
    "        theta_p = theta.copy()\n",
    "        theta_n = theta.copy()\n",
    "        theta_p[i] = theta[i] + eps\n",
    "        theta_n[i] = theta[i] - eps\n",
    "        grad[i] = (J(theta_p) - J(theta_n)) / eps2\n",
    "    return grad\n",
    "\n",
    "def check_numerical_gradient():\n",
    "    x = np.array([4, 10], dtype = np.float64)\n",
    "    value, grad = simple_quadratic_function(x)\n",
    "    func = lambda x: simple_quadratic_function(x)[0]\n",
    "    numgrad = compute_numerical_gradient(func, x)\n",
    "    \n",
    "    n_grad = grad.size\n",
    "    for i in range(n_grad):\n",
    "        print \"{0:20.12f} {1:20.12f}\".format(numgrad[i], grad[i])\n",
    "    print 'The above two columns you get should be very similar.\\n(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n'\n",
    "\n",
    "    diff = np.linalg.norm(numgrad - grad) / np.linalg.norm(numgrad + grad)\n",
    "    print \"Norm of difference = \", diff\n",
    "    print 'Norm of the difference between numerical and analytical gradient (should be < 1e-9)\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_numerical_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions need to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(hidden_size, visible_size):\n",
    "    r  = np.sqrt(6) / np.sqrt(hidden_size + visible_size + 1)\n",
    "    W1 = np.random.random((hidden_size, visible_size)) * 2.0 * r - r\n",
    "    W2 = np.random.random((visible_size, hidden_size)) * 2.0 * r - r\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    b2 = np.zeros(visible_size)\n",
    "    theta = np.hstack((W1.ravel(), W2.ravel(), b1.ravel(), b2.ravel()))\n",
    "    return theta\n",
    "\n",
    "def display_network(A):\n",
    "    opt_normalize = True\n",
    "    opt_graycolor = True\n",
    "\n",
    "    A = A - np.average(A)\n",
    "\n",
    "    (row, col) = A.shape\n",
    "    sz = int(np.ceil(np.sqrt(row)))\n",
    "    buf = 1\n",
    "    n = np.ceil(np.sqrt(col))\n",
    "    m = np.ceil(col / n)\n",
    "    \n",
    "    img_shape1 = int(buf + m * (sz + buf))\n",
    "    img_shape2 = int(buf + n * (sz + buf))\n",
    "    image = np.ones(shape=(img_shape1, img_shape2))\n",
    "\n",
    "    if not opt_graycolor:\n",
    "        image *= 0.1\n",
    "\n",
    "    k = 0\n",
    "    for i in range(int(m)):\n",
    "        for j in range(int(n)):\n",
    "            if k >= col:\n",
    "                continue\n",
    "            clim = np.max(np.abs(A[:, k]))\n",
    "            if opt_normalize:\n",
    "                image[buf + i * (sz + buf):buf + i * (sz + buf) + sz, buf + j * (sz + buf):buf + j * (sz + buf) + sz] = \\\n",
    "                    A[:, k].reshape(sz, sz) / clim\n",
    "            else:\n",
    "                image[buf + i * (sz + buf):buf + i * (sz + buf) + sz, buf + j * (sz + buf):buf + j * (sz + buf) + sz] = \\\n",
    "                    A[:, k].reshape(sz, sz) / np.max(np.abs(A))\n",
    "            k += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0\n",
    "patches = sample_images('IMAGES.mat')\n",
    "n_patches = patches.shape[1]\n",
    "\n",
    "image = display_network(patches[: , [np.random.randint(n_patches) for i in range(200)]])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.imsave('sparse_autoencoder_patches.png', image, cmap=plt.cm.gray)\n",
    "\n",
    "\n",
    "# Step 1\n",
    "visible_size = patches.shape[0]\n",
    "hidden_size = 25\n",
    "\n",
    "weight_decay_param = 0.0001 # weight decay parameter, which is the lambda in lecture notes\n",
    "beta = 3                    # weight of sparsity penalty term\n",
    "sparsity_param = 0.01       # desired average activation of the hidden units.\n",
    "theta = initialize_parameters(hidden_size, visible_size)\n",
    "\n",
    "\n",
    "# Step 2\n",
    "cost, grad = sparse_autoencoder_cost(theta, visible_size, hidden_size, weight_decay_param, sparsity_param, beta, patches)\n",
    "\n",
    "\n",
    "# Step 3\n",
    "debug = True\n",
    "\n",
    "if debug:\n",
    "    check_numerical_gradient()\n",
    "\n",
    "    J = lambda theta : sparse_autoencoder_cost(theta, visible_size, hidden_size,\n",
    "        weight_decay_param, sparsity_param, beta, patches)[0]\n",
    "    numgrad = compute_numerical_gradient(J, theta)\n",
    "\n",
    "    n = min(grad.size, 20)\n",
    "    for i in range(n):\n",
    "        print \"{0:20.12f} {1:20.12f}\".format(numgrad[i], grad[i])\n",
    "    print 'The above two columns you get should be very similar.\\n(Left-Your Numerical Gradient, Right-Analytical Gradient)\\n'\n",
    "\n",
    "    diff = np.linalg.norm(numgrad - grad) / np.linalg.norm(numgrad + grad)\n",
    "    print \"Norm of difference = \", diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 4: After verifying that your implementation of\n",
    "  sparse_autoencoder_cost is correct, You can start training your sparse\n",
    "  autoencoder with minFunc (L-BFGS).\n",
    "\"\"\"\n",
    "#  Randomly initialize the parameters\n",
    "theta = initialize_parameters(hidden_size, visible_size)\n",
    "\n",
    "J = lambda theta : sparse_autoencoder_cost(theta, visible_size, hidden_size,\n",
    "    weight_decay_param, sparsity_param, beta, patches)\n",
    "\n",
    "# In case you want to see the details of optimization,\n",
    "# Please set 'disp' as True\n",
    "options = {'maxiter': 400, 'disp': True, 'gtol': 1e-5, 'ftol': 2e-9}\n",
    "results = scipy.optimize.minimize(J, theta, method='L-BFGS-B', jac=True, options=options)\n",
    "opt_theta = results['x']\n",
    "\n",
    "print(\"Show the results of optimization as following.\\n\")\n",
    "print(results)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STEP 5: Visualization\n",
    "\"\"\"\n",
    "W1 = opt_theta[0:hidden_size*visible_size].reshape((hidden_size, visible_size))\n",
    "\n",
    "print(\"Save and show the W1\")\n",
    "image = display_network(W1.T)\n",
    "\n",
    "plt.figure()\n",
    "plt.imsave('sparse_autoencoder_weights.png', image, cmap=plt.cm.gray)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
